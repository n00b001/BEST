# model-adjustments.yaml
adjustments:
  # Top Tier Coding Models (Professional Grade)
  "(?i)gpt-?4(-|_)turbo(preview)?"": 85
  "(?i)deepseek(-|_)?r1": 100
  "(?i)deepseek(-|_)?r1(-|_)?zero": 90
  "(?i)deepseek(-|_)?r1(-|_)?distill": 50
  "(?i)codestral(-|_)?(22b|24b|25b)": 97
  "(?i)codestral": 80
  "(?i)gpt-?4-0613": 95
  "(?i)codellama(-|_)?70b.*instruct": 90
  "(?i)deepseek(-|_)?coder(-|_)?33b.*instruct": 88
  "(?i)codeqwen(-|_)?1\.5-72b.*chat": 85
  "(?i)starcoder2(-|_)?15b": 80

  # Strong Mid-Tier Coding Models
  "(?i)mixtral(-|_)?8x22b.*instruct": 84
  "(?i)wizardcoder(-|_)?33b.*v1\.1": 78
  "(?i)phind.*codellama.*34b.*v2": 75
  "(?i)gpt-?3\.5.*turbo": 50

  # Vendor Models
  "(?i)claude-?3(-|_)?(5|6).*sonnet": 80
  "(?i)gemini(-|_)?pro": 50
  "(?i)mistral(-|_)?small": 30

  # Size-based Adjustments
  "(?i).*-tiny(-|_)": -10
  "(?i).*-small(-|_)": -5
  "(?i).*-medium(-|_)": 0
  "(?i).*-large(-|_)": 30

  # Specialized Models
  "(?i).*coder.*": 30
  "(?i).*qwq.*": 60
  "(?i)deepseek(-|_)?v3": 80

  # Deprioritization Patterns
  "(?i).*embed.*": -100
  "(?i).*dalle.*": -100
  "(?i).*whisper.*": -100
  "(?i).*tts.*": -100
  "(?i)moderation": -100
  "(?i).*auto.*": -3000
  "(?i).*flux.*": -3000
  "(?i).*stablediffusion.*": -100

  # Version Handling
  "(?i)gpt-?4.*32k": 95
  "(?i)mixtral(-|_)?8x7b.*instruct": 63
  "(?i)claude-?2\..*": 40

  # Architecture Patterns
  "(?i)\d+[bm]b": 20  # Matches any model size suffix (e.g. 7b, 70b)
  "(?i)\d+x\d+[bm]": 25  # Matches mixture-of-expert patterns